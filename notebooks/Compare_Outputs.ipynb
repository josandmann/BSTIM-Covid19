{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "import cProfile\n",
    "import pstats\n",
    "%run ../src/sampling_utils.py\n",
    "%run ../src/shared_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The always stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/counties/counties.pkl', \"rb\") as f:\n",
    "    counties = pkl.load(f)\n",
    "    \n",
    "disease = \"covid19\"\n",
    "prediction_region = \"germany\"\n",
    "\n",
    "indata = load_daily_data(disease, prediction_region, counties)\n",
    "data = indata.iloc[:,0:31]\n",
    "#data = indata.iloc[:,0:31]\n",
    "rnd_tsel = np.random.Generator(np.random.PCG64(12345))\n",
    "times_by_day = uniform_times_by_day(data.index, rnd_tsel)\n",
    "\n",
    "rnd_csel = np.random.Generator(np.random.PCG64(12345))\n",
    "locations_by_county=uniform_locations_by_county(counties, rnd_csel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample_time_and_space() missing 6 required positional arguments: 'day_of_smpl', 'av_times_per_smpl', 'cnty_of_smpl', 'av_locs_per_smpl', 'rnd_time', and 'rnd_loc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a149b065e2d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt_data_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_pred_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_pred_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mt_data_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_pred_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_pred_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_ia_effects_old\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-a149b065e2d1>\u001b[0m in \u001b[0;36msample_ia_effects_old\u001b[1;34m()\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mday\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mt_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_time_and_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes_by_day\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations_by_county\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mt_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_time_and_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_tps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounty\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes_by_day\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocations_by_county\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_time_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_loc_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sample_time_and_space() missing 6 required positional arguments: 'day_of_smpl', 'av_times_per_smpl', 'cnty_of_smpl', 'av_locs_per_smpl', 'rnd_time', and 'rnd_loc'"
     ]
    }
   ],
   "source": [
    "rnd_time = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc  = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_time_pred = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc_pred  = np.random.Generator(np.random.PCG64(12345))\n",
    "\n",
    "\n",
    "def gaussian_bf(dx, σ):\n",
    "    \"\"\" spatial basis function \"\"\"\n",
    "    σ = np.float32(σ)\n",
    "    res = tt.zeros_like(dx)\n",
    "    idx = (abs(dx) < np.float32(5) * σ)  # .nonzero()\n",
    "    return tt.set_subtensor(res[idx], tt.exp(\n",
    "        np.float32(-0.5 / (σ**2)) * (dx[idx])**2) / np.float32(np.sqrt(2 * np.pi * σ**2)))\n",
    "\n",
    "\n",
    "def bspline_bfs(x, knots, P):\n",
    "    \"\"\" temporal basis function\n",
    "            x: t-delta distance to last knot (horizon 5)\n",
    "    \"\"\"\n",
    "    knots = knots.astype(np.float32)\n",
    "    idx = ((x >= knots[0]) & (x < knots[-1]))  # .nonzero()\n",
    "    xx = x[idx]\n",
    "\n",
    "    N = {}\n",
    "    for p in range(P + 1):\n",
    "        for i in range(len(knots) - 1 - p):\n",
    "            if p == 0:\n",
    "                N[(i, p)] = tt.where((knots[i] <= xx)\n",
    "                                     * (xx < knots[i + 1]), 1.0, 0.0)\n",
    "            else:\n",
    "                N[(i, p)] = (xx - knots[i]) / (knots[i + p] - knots[i]) * N[(i, p - 1)] + \\\n",
    "                    (knots[i + p + 1] - xx) / (knots[i + p + 1] - knots[i + 1]) * N[(i + 1, p - 1)]\n",
    "\n",
    "    highest_level = []\n",
    "    for i in range(len(knots) - 1 - P):\n",
    "        res = tt.zeros_like(x)\n",
    "        highest_level.append(tt.set_subtensor(res[idx], N[(i, P)]))\n",
    "    return highest_level\n",
    "\n",
    "\n",
    "#NOTE: Do we want basis functions with a longer temporal horizon? // we may want to weight them around fixed days?!\n",
    "#NOTE: Split this up, so we can get multiple basis functions!\n",
    "def temporal_bfs(x):\n",
    "    return bspline_bfs(x, np.array([0, 0, 1, 2, 3, 4, 5]) * 24 * 3600.0, 2) \n",
    "\n",
    "\n",
    "def spatial_bfs(x):\n",
    "    return [gaussian_bf(x, σ) for σ in [6.25, 12.5, 25.0, 50.0]]\n",
    "\n",
    "\n",
    "def jacobian_sq(latitude, R=6365.902):\n",
    "    \"\"\"\n",
    "        jacobian_sq(latitude)\n",
    "\n",
    "    Computes the \"square root\" (Cholesky factor) of the Jacobian of the cartesian projection from polar coordinates (in degrees longitude, latitude) onto cartesian coordinates (in km east/west, north/south) at a given latitude (the projection's Jacobian is invariante wrt. longitude).\n",
    "    TODO: don't import jacobian_sq from geo_utils to remove potential conflicts\n",
    "    \"\"\"\n",
    "    return R * (np.pi / 180.0) * (abs(tt.cos(tt.deg2rad(latitude))) *\n",
    "                                  np.array([[1.0, 0.0], [0.0, 0.0]]) + np.array([[0.0, 0.0], [0.0, 1.0]]))\n",
    "\n",
    "\n",
    "def build_ia_bfs(temporal_bfs, spatial_bfs, profile):\n",
    "    x1 = tt.fmatrix(\"x1\")\n",
    "    t1 = tt.fvector(\"t1\")\n",
    "    # M = tt.fmatrix(\"M\")\n",
    "    x2 = tt.fmatrix(\"x2\")\n",
    "    t2 = tt.fvector(\"t2\")\n",
    "\n",
    "    lat = x1[:, 1].mean()\n",
    "    M = jacobian_sq(lat)**2\n",
    "\n",
    "    # (x1,t1) are the to-be-predicted points, (x2,t2) the historic cases\n",
    "\n",
    "    # spatial distance btw. each points (defined with latitude,longitude) in x1 and x2 with gramian M\n",
    "    # (a-b)^2 = a^2 + b^2 -2ab; with a,b=vectors\n",
    "    dx = tt.sqrt(  (x1.dot(M) * x1).sum(axis=1).reshape((-1,  1)) # a^2\n",
    "                 + (x2.dot(M) * x2).sum(axis=1).reshape(( 1, -1)) # b^2\n",
    "                 - 2 * x1.dot(M).dot(x2.T) )                      # -2ab\n",
    "\n",
    "    # temporal distance btw. each times in t1 and t2\n",
    "    dt = t1.reshape((-1, 1)) - t2.reshape((1, -1))\n",
    "\n",
    "    ft = tt.stack(temporal_bfs(dt.reshape((-1,))), axis=0) # cast to floats?\n",
    "    fx = tt.stack(spatial_bfs(dx.reshape((-1,))), axis=0)\n",
    "\n",
    "    # aggregate contributions of all cases\n",
    "    contrib = ft.dot(fx.T).reshape((-1,)) / tt.cast(x1.shape[0], \"float32\")\n",
    "\n",
    "    return theano.function([t1, x1, t2, x2], contrib, allow_input_downcast=True, profile=profile)\n",
    "\n",
    "ia_bfs = build_ia_bfs(temporal_bfs, spatial_bfs, profile=False)\n",
    "\n",
    "\n",
    "\n",
    "def sample_ia_effects_old():\n",
    "    t_data_0 = []\n",
    "    x_data_0 = []\n",
    "    t_pred_0 = []\n",
    "    x_pred_0 = []\n",
    "\n",
    "    num_tps=5\n",
    "    d_offs=0 # just to limit the time of test\n",
    "    c_offs=0 # just to limit the time of test\n",
    "    days = data.index[d_offs:d_offs+50]\n",
    "    counties = data.columns[c_offs:c_offs+50]\n",
    "\n",
    "    _to_timestamp = np.frompyfunc(datetime.datetime.timestamp, 1, 1)\n",
    "    num_features = len(temporal_bfs(tt.fmatrix(\"tmp\"))) * len(spatial_bfs(tt.fmatrix(\"tmp\")))\n",
    "    res_0 = np.zeros((len(days), len(counties), num_features), dtype=np.float32)\n",
    "\n",
    "    for i, day in enumerate(days):\n",
    "        for j, county in enumerate(counties):\n",
    "            idx = ((day - pd.Timedelta(days=5)) <= data.index) * (data.index < day)\n",
    "\n",
    "            t_data, x_data = sample_time_and_space(data.iloc[idx], times_by_day, locations_by_county, rnd_time, rnd_loc)\n",
    "            t_pred, x_pred = sample_time_and_space(pd.DataFrame(num_tps, index=[day], columns=[county]), times_by_day, locations_by_county, rnd_time_pred, rnd_loc_pred)\n",
    "\n",
    "            #print(\"_to_timestamp(t_pred) (types, type1, size, value): \", type(_to_timestamp(t_pred)), type(_to_timestamp(t_pred)[0]), np.shape(_to_timestamp(t_pred)), _to_timestamp(t_pred)[0])\n",
    "            # => _to_timestamp(t_pred) (types, type1, size, value):  <class 'numpy.ndarray'> <class 'float'> (5,) 1580217693.876309\n",
    "            #print(\"x_pred (types, size, value)       : \", type(x_pred), type(x_pred[0]), type(x_pred[0][0]), np.shape(x_pred), x_pred[0][0])        \n",
    "            # => x_pred (types, size, value)       :  <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float64'> (5, 2) 10.134378974970323\n",
    "\n",
    "            res_0[i, j, :] = ia_bfs(_to_timestamp(t_pred), x_pred, _to_timestamp(t_data), x_data)        \n",
    "\n",
    "            # store all to compare with old algo\n",
    "            t_data_0 = t_data_0 + t_data.tolist()\n",
    "            x_data_0 = x_data_0 + x_data.tolist()\n",
    "            t_pred_0 = t_pred_0 + t_pred.tolist()\n",
    "            x_pred_0 = x_pred_0 + x_pred.tolist()\n",
    "            \n",
    "    return t_data_0, x_data_0, t_pred_0, x_pred_0\n",
    "\n",
    "t_data_0, x_data_0, t_pred_0, x_pred_0 = sample_ia_effects_old()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#ia_bfs = build_ia_bfs(temporal_bfs, spatial_bfs, profile=False)\n",
    "#%%timeit\n",
    "#cp = cProfile.Profile()\n",
    "#cp.enable()\n",
    "samp = iaeffect_sampler(data, times_by_day, locations_by_county, temporal_bfs, spatial_bfs)\n",
    "#cp.disable()\n",
    "#cp.create_stats()\n",
    "#p = pstats.Stats()\n",
    "#p.strip_dirs()\n",
    "#cp.dump_stats('profilenumbasingle.dmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(data))\n",
    "#print(np.shape(data.index))\n",
    "#print(np.shape(data.columns))\n",
    "#print(type(samp), type(samp[0]), type(samp[0][0]), type(samp[0][0][0]))\n",
    "#print(not 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
