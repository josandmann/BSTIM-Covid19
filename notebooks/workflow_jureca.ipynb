{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "from IPython import get_ipython\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "class IpyExit(SystemExit):\n",
    "    \"\"\"Exit Exception for IPython.\n",
    "\n",
    "    Exception temporarily redirects stderr to buffer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"exiting\")\n",
    "        sys.stderr = StringIO()\n",
    "\n",
    "    def __del__(self):\n",
    "        sys.stderr.close()\n",
    "        sys.stderr = sys.__stderr__  # restore from backup\n",
    "\n",
    "def ipy_exit():\n",
    "    raise IpyExit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "## Prepare Source, Data and Directories\n",
    "- set input/output directories and user settings\n",
    "- download source from github\n",
    "- replace data directory with precomputed one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REQUIREMENTS:**\n",
    "   - you have joined the project `covid19dynstat`\n",
    "   - you have created the directory `$PROJECT_covid19dynstat/$USER`\n",
    "   - you have copied/linked a `data` directory to `$PROJECT_covid19dynstat/$USER/data`\n",
    "       - will replace `data` from git repository\n",
    "       - MUST include `counties/counties.pkl` (explicitly for JURECA, not from git repo!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed parameters\n",
    "user_email = \"user@email.de\"\n",
    "cmpprj_name = \"covid19dynstat\" # do not change (used in slurm-file)\n",
    "\n",
    "# run:\n",
    "run_name = \"BSTIM-Covid19_001\"\n",
    "\n",
    "# source: clone only first time with 'run_name'\n",
    "git_repo = \"https://github.com/neuroinfo-os/BSTIM-Covid19.git\"\n",
    "git_branch = \"master\"\n",
    "\n",
    "# csv: update if missing or requested\n",
    "csv_rki = True # get csv from RKI\n",
    "csv_update = False # update csv even if already existing\n",
    "\n",
    "# run slurm dependency chain\n",
    "slurm_chain = False\n",
    "\n",
    "# simulation: sample_ia\n",
    "# nodes * taskpernode = num_sample defined in src/sample_ia_effects.py\n",
    "submit_job_ia   = True\n",
    "job_ia_nodes        = 5 # 5\n",
    "job_ia_taskspernode = 20 # 20\n",
    "job_ia_runtime      = '5:00:00' # '5:00:00' (JURECA + 1h)\n",
    "\n",
    "# simulation: sample_posterior\n",
    "# nodes * taskpernode = len(combinations) defined in src/config.py\n",
    "submit_job_post   = False\n",
    "job_post_nodes        = 1 # 1\n",
    "job_post_taskspernode = 4 # 4\n",
    "job_post_runtime      = '18:00:00' # '18:00:00' (JURECA + 1h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input/output directories and user settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check users project directory\n",
    "# (do NOT change as it is used in SLURM-jobscript, too)\n",
    "user_proj_dir = os.path.join(os.getenv('PROJECT_'+cmpprj_name), os.getenv('USER'))\n",
    "if not os.path.isdir(user_proj_dir):\n",
    "    print(\"ERROR: project directory has no directory of the current user.\")\n",
    "    print(\"       please create \", user_proj_dir)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"user_proj_dir = \", user_proj_dir)\n",
    "    \n",
    "# check for SLURM output directory\n",
    "# (do not change as it is set in SLURM-jobscript, too)\n",
    "slurm_out_dir = os.path.join(user_proj_dir, 'run')\n",
    "if not os.path.isdir(user_proj_dir):\n",
    "    print(\"ERROR: SLURM output directory does not exist.\")\n",
    "    print(\"       please create \", slurm_out_dir)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"slurm_out_dir = \", slurm_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from git import Repo\n",
    "\n",
    "# auto-generate run_name if empty\n",
    "if not run_name:\n",
    "    run_name = datetime.now().strftime(\"BSTIM-Covid19_%Y-%m-%d_%H-%M-%S_\" + git_branch)\n",
    "\n",
    "# set source_dir\n",
    "source_dir = os.path.join(user_proj_dir, run_name)\n",
    "print(\"source_dir = \", source_dir)\n",
    "\n",
    "# set source_data_dir\n",
    "source_data_dir = os.path.join(source_dir, 'data')\n",
    "print(\"source_data_dir = \", source_data_dir)\n",
    "\n",
    "# clone source if required\n",
    "if not os.path.exists(source_dir):\n",
    "    print(\"cloning git repository\")\n",
    "\n",
    "    if not git_branch:\n",
    "        git_branch = 'master'\n",
    "    print(\"git_branch = \", git_branch)\n",
    "\n",
    "    if not git_repo:\n",
    "        git_repo = 'https://github.com/neuroinfo-os/BSTIM-Covid19.git'\n",
    "    print(\"git_repo = \", git_repo)\n",
    "\n",
    "    repo = Repo.clone_from(git_repo, source_dir, branch=git_branch)\n",
    "    #repo.heads['tag-name'].checkout() # checkout a certain tag\n",
    "\n",
    "    # rename data dir if from clean checkout\n",
    "    if os.path.exists(source_data_dir):\n",
    "        os.rename(source_data_dir,  os.path.join(source_dir,'data_git'))\n",
    "else:\n",
    "    print(\"NO cloning of git repository\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pkg_resources\n",
    "from pkg_resources import DistributionNotFound, VersionConflict\n",
    "\n",
    "source_reqtxt_file = os.path.join(source_dir, 'requirements.txt')\n",
    "if os.path.exists(source_reqtxt_file):\n",
    "    with open(source_reqtxt_file) as f:\n",
    "        dependencies = f.readlines()\n",
    "    dependencies = [x.strip() for x in dependencies] \n",
    "\n",
    "    for d in dependencies:\n",
    "        if d == \"pkg-resources==0.0.0\":\n",
    "            continue\n",
    "        try:\n",
    "            pkg_resources.require(d)\n",
    "        except pkg_resources.DistributionNotFound as e:\n",
    "            print(\"MISSING package: \", e)\n",
    "        except pkg_resources.VersionConflict as e:\n",
    "            print(\"WRONG version: \", e)\n",
    "else:\n",
    "    print(\"requirements.txt not found at \", source_reqtxt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace data directory with precomputed one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# copy new data dir with precomputed pickel file\n",
    "# if data directory does not exist\n",
    "if not os.path.exists(source_data_dir):\n",
    "    print(\"replacing data directory\")\n",
    "    user_data_dir = os.path.join(user_proj_dir, 'data')\n",
    "    if os.path.exists(user_data_dir) and os.path.isdir(user_data_dir):\n",
    "        shutil.copytree(user_data_dir, source_data_dir)\n",
    "    else:\n",
    "        print(\"ERROR: user data directory does not exists or is no directory.\")\n",
    "        raise IpyExit\n",
    "else:\n",
    "    print(\"NO replacing of data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "## Get COVID-19 data from RKI\n",
    "Covid-19 data is provided by the [Robert Koch Institute][4] via the publically accessiable [this](https://npgeo-corona-npgeo-de.hub.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0/data?orderBy=Meldedatum) link.  \n",
    "We download the CSV table and store it in `./data/raw/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy COVID-19 data from data-git (if csv_rki == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "raw_csv_fpath = os.path.join(source_data_dir, 'raw', \"covid19.csv\")\n",
    "print(\"raw_csv_fpath = \", raw_csv_fpath)\n",
    "\n",
    "data_basename = os.path.basename(raw_csv_fpath)\n",
    "datagit_csv_fpath = os.path.join(source_dir, \"data_git\", \"diseases\", data_basename)\n",
    "if os.path.exists(datagit_csv_fpath):\n",
    "    print(\"datagit_csv_fpath = \", datagit_csv_fpath)\n",
    "    \n",
    "    data_csv_fpath = os.path.join(source_dir, \"data\", \"diseases\", data_basename)\n",
    "    print(\"data_csv_fpath = \", data_csv_fpath)\n",
    "\n",
    "    # only if update is requested\n",
    "    if os.path.exists(data_csv_fpath) and csv_update:\n",
    "        \n",
    "        # copy csv from data_git instead of downloading\n",
    "        if not csv_rki:\n",
    "            shutil.copyfile(datagit_csv_fpath, data_csv_fpath)\n",
    "            print(\"copy\", data_basename, \"from git ... SUCCESS\")\n",
    "        else:\n",
    "            print(\"NO copying - download from RKI requested\")\n",
    "    else:\n",
    "        print(\"NO csv update\")\n",
    "else:\n",
    "    print(\"data_csv_fpath = MISSING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download COVID-19 CSV (if csv_rki == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# download csv data if asked for\n",
    "if csv_rki and not os.path.exists(raw_csv_fpath) or csv_update:\n",
    "    print('download COVID-19 data')\n",
    "\n",
    "    raw_csv_url = 'https://opendata.arcgis.com/datasets/dd4580c810204019a7b8eb3e0b329dd6_0.csv'\n",
    "    raw_csv_red = requests.get(raw_csv_url, allow_redirects=True)\n",
    "    print(\"raw_csv_url = \", raw_csv_url)\n",
    "\n",
    "    open(raw_csv_fpath, 'wb').write(raw_csv_red.content)\n",
    "else:\n",
    "    print(\"NO download of COVID-19 data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess COVID-19 CSV (if csv_rki == True)\n",
    "The downloadable CSV table can be found in `./data/raw/` and is preprocessed to fit the BSTI Model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv_fpath = os.path.join(os.path.dirname(raw_csv_fpath), \"..\", \"diseases\", os.path.basename(raw_csv_fpath))\n",
    "print(\"data_csv_fpath = \", data_csv_fpath)\n",
    "\n",
    "# skip preprocessiong\n",
    "#if not csv_rki or os.path.exists(data_csv_fpath) and not csv_update:\n",
    "#    if os.path.exists(data_csv_fpath) or not csv_update:\n",
    "#        print(\"NO preprocessing csv\")\n",
    "#        raise StopExecution\n",
    "\n",
    "# do preprocessing\n",
    "preprocess_python = os.path.join(source_dir, 'src', \"preprocess_covid19_table.py\")\n",
    "if not os.path.exists(preprocess_python):\n",
    "    print(\"ERROR: cannot find \", preprocess_python)\n",
    "    raise IpyExit\n",
    "print(\"preprocess_python = \", preprocess_python)\n",
    "\n",
    "data_shapes_fpath = os.path.join(os.path.dirname(raw_csv_fpath), 'germany_county_shapes.json')\n",
    "if not os.path.exists(data_shapes_fpath):\n",
    "    print(\"ERROR: cannot find \", data_shapes_fpath)\n",
    "    raise IpyExit\n",
    "print(\"data_shapes_fpath = \", data_shapes_fpath)    \n",
    "\n",
    "regex_Meldedatum = r'([0-9]{4})\\/([0-9]{2})\\/([0-9]{2}).*'\n",
    "dayformat_Meldedatum = r'{:04d}/{:02d}/{:02d} 00:00:00'\n",
    "%run $preprocess_python --source \"$raw_csv_fpath\" --destination \"$data_csv_fpath\" --shapes \"$data_shapes_fpath\" --regex \"$regex_Meldedatum\" --dayformat \"$dayformat_Meldedatum\"\n",
    "print(\" finished\")\n",
    "\n",
    "total = 0        \n",
    "with open(data_csv_fpath) as fin:\n",
    "    reader = csv.reader(fin)\n",
    "    next(reader, None)  # skip the headers\n",
    "    for row in reader:\n",
    "        total += sum(map(int, row[1:]))\n",
    "    print(\"infections = \", total)\n",
    "    if total <= 0:\n",
    "        print(\"ERROR: csv data probably wrong\")\n",
    "        raise IpyExit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count infections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "if not os.path.isfile(data_csv_fpath):\n",
    "    print(\"ERROR: file data/covid19.csv is missing\")\n",
    "    raise IpyExit\n",
    "        \n",
    "total = 0\n",
    "with open(data_csv_fpath) as fin:\n",
    "    reader = csv.reader(fin)\n",
    "    next(reader, None)  # skip the headers\n",
    "    for row in reader:\n",
    "        total += sum(map(int, row[1:]))\n",
    "    print(\"infections = \", total)\n",
    "    if total <= 0:\n",
    "        print(\"ERROR: csv data probably wrong\")\n",
    "        raise IpyExit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Simulation 1: Sample Interaction Effects (100x)\n",
    "`sample_ia_effects.py` reads  \n",
    "- ../data/counties/counties.pkl\n",
    "- ../data/diseases/{covid19}.csv\n",
    "\n",
    "and outputs:\n",
    "- ../data/ia_effect_samples/{}_{}.pkl\n",
    "\n",
    "sample_ia_effects.py is called 100x by SLURM (=farming) and calculates the same thing with different random numbers:  \n",
    "- gridjob_sample_ia.slurm \n",
    "  - `#SBATCH --array=1-100:4`\n",
    "- gridjob_sample_ia.slurm.sh\n",
    "  - `THEANO_FLAGS=\"base_compiledir=${TASK_DIR}/,floatX=float32,device=cpu,openmp=True,mode=FAST_RUN,warn_float64=warn\" OMP_NUM_THREADS=8  python3 sample_ia_effects.py > ${TASK_DIR}/log.txt`\n",
    "- sample_ia_effects.py\n",
    "  - ```nums_sample = range(100)\n",
    "GID = int(os.environ[\"SGE_TASK_ID\"])\n",
    "num_sample = nums_sample[GID - 1]\n",
    "filename = \"../data/ia_effect_samples/{}_{}.pkl\".format(disease, num_sample)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# slurm jobfile\n",
    "slurm_jobfile_ia = os.path.join(source_dir, 'src', \"gridjob_sample_ia.slurm\")\n",
    "if not os.path.exists(slurm_jobfile_ia):\n",
    "    print(\"ERROR: original SLURM job file does not exist\")\n",
    "    print(\"       please check for \", slurm_jobfile_ia)\n",
    "    raise IpyExit\n",
    "print(\"slurm_jobfile_ia = \", slurm_jobfile_ia)\n",
    "    \n",
    "slurm_shfile_ia = os.path.join(source_dir, 'src', \"gridjob_sample_ia.slurm.sh\")\n",
    "if not os.path.exists(slurm_shfile_ia):\n",
    "    print(\"ERROR: original SLURM sh file does not exist\")\n",
    "    print(\"       please check for \", slurm_shfile_ia)\n",
    "    raise IpyExit\n",
    "print(\"slurm_shfile_ia = \", slurm_shfile_ia)\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_ia, os.X_OK):\n",
    "    with open(slurm_shfile_ia, \"r\") as fd:\n",
    "        os.chmod(fd.fileno(), 0o755)\n",
    "\n",
    "if submit_job_ia:\n",
    "    \n",
    "    # check required input\n",
    "    file_counties = os.path.join(source_data_dir, 'counties', 'counties.pkl')\n",
    "    if not os.path.isfile(file_counties):\n",
    "        print(\"ERROR: file data/counties.pkl is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        print(\"file_counties = \", file_counties)\n",
    "        \n",
    "    file_covid19 = os.path.join(source_data_dir, 'diseases', 'covid19.csv')\n",
    "    if not os.path.isfile(file_covid19):\n",
    "        print(\"ERROR: file data/covid19.csv is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        total = 0        \n",
    "        with open(file_covid19) as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            next(reader, None)  # skip the headers\n",
    "            for row in reader:\n",
    "                total += sum(map(int, row[1:]))\n",
    "        print(\"infections = \", total)\n",
    "        if total <= 0:\n",
    "            print(\"ERROR: csv data probably wrong\")\n",
    "            raise IpyExit\n",
    "    print(\"file_covid19 = \", file_covid19)\n",
    "    \n",
    "    # check output directory\n",
    "    dir_iaeffect = os.path.join(source_data_dir, 'ia_effect_samples')\n",
    "    if not os.path.exists(dir_iaeffect):\n",
    "        os.mkdir(dir_iaeffect)    \n",
    "    if not os.path.isdir(dir_iaeffect):\n",
    "        print(\"ERROR: \" + dir_iaeffect + \" not a directroy\")\n",
    "        raise IpyExit\n",
    "    if os.listdir(dir_iaeffect):\n",
    "        print(\"ERROR: directory \" + dir_iaeffect + \" not empty\")\n",
    "        raise IpyExit\n",
    "    print(\"dir_iaeffect = \", dir_iaeffect)\n",
    "    \n",
    "else:\n",
    "    print(\"NO checking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare SLURM job file (sample_ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "def prepare_jobfile_ia(slurm_jobfile_ia):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_jobfile_ia, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"#SBATCH --array=1-{}:{}\\n\".format(job_ia_nodes * job_ia_taskspernode, job_ia_taskspernode) if \"#SBATCH --array=\" in line else line\n",
    "            line = \"#SBATCH --ntasks-per-node={}\\n\".format(job_ia_taskspernode) if \"#SBATCH --ntasks-per-node=\" in line else line\n",
    "            line = \"#SBATCH --nodes=1\\n\"                        if \"#SBATCH --nodes=\"       in line else line\n",
    "            line = \"#SBATCH --time={}\\n\".format(job_ia_runtime) if \"#SBATCH --time=\"        in line else line\n",
    "            line = \"#SBATCH --mail-type=ALL\\n\"                  if \"# #SBATCH --mail-type=\" in line else line\n",
    "            line = \"#SBATCH --mail-user=\" + user_email + '\\n'   if \"# #SBATCH --mail-user=\" in line else line\n",
    "            line = \"# mkdir -p ${PROJECT}/${USER}/runs/\\n\" if \"mkdir -p ${PROJECT}/${USER}/runs/\" in line else line\n",
    "            line = \"srun -n ${SLURM_NTASKS} gridjob_sample_ia.slurm.sh\" if \"srun --exclusive -n ${SLURM_NTASKS} gridjob_sample_ia.slurm.sh\\n\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_ia:\n",
    "    prepare_jobfile_ia(slurm_jobfile_ia)\n",
    "    with open(slurm_jobfile_ia, 'r') as sfile:\n",
    "        print(sfile.read())\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit SLURM job (sample_ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from subprocess import (Popen, PIPE)\n",
    "\n",
    "def submit_job(slurm_jobfile, submit_dir, sbatch_addargs=''):\n",
    "    print(\"submitting slurm job\")\n",
    "    \n",
    "    # build sbatch command\n",
    "    sbatch_args = sbatch_addargs + \" \" + slurm_jobfile\n",
    "    sbatch_cmd = ['sbatch'] + sbatch_args.split()\n",
    "    print(\"sbatch_cmd = \", sbatch_cmd)\n",
    "\n",
    "    # submit SLURM job\n",
    "    process = Popen(sbatch_cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, cwd=submit_dir)\n",
    "    \n",
    "    # block until finished and output stdout, stderr\n",
    "    stdout, stderr = process.communicate() \n",
    "    sbatch_out = stdout.decode(\"utf-8\")\n",
    "    sbatch_err = stderr.decode(\"utf-8\")\n",
    "    \n",
    "    print(\"---- stdout ----\")        \n",
    "    print(sbatch_out)\n",
    "    print(\"---- stderr ----\")\n",
    "    print(sbatch_err)\n",
    "        \n",
    "    if process.returncode != 0:\n",
    "        raise IpyExit\n",
    "    \n",
    "    # get SLURM job id\n",
    "    slurm_jobid = ''\n",
    "    if sbatch_out:\n",
    "        slurm_jobid = sbatch_out.split()[-1]\n",
    "    print(\"slurm_jobid = \", slurm_jobid)\n",
    "\n",
    "    # save SLURM job id to file\n",
    "    if slurm_jobid:\n",
    "        with open(os.path.join(submit_dir, slurm_jobfile + \".sbatchout\"), \"w\") as ofile:\n",
    "            print(\"jobid: {}\".format(slurm_jobid), file=ofile)\n",
    "\n",
    "submit_dir_ia = os.path.join(source_dir, 'src')\n",
    "print(\"submit_dir_ia = \", submit_dir_ia)\n",
    "\n",
    "if submit_job_ia:\n",
    "    submit_job(slurm_jobfile_ia, submit_dir_ia, '-vv')\n",
    "    \n",
    "    # better wait for a few seconds to ensure slurm has processed the new job internally\n",
    "    # this ensures, that squeue will show at least some information\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show status of submitted job (sample_ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import (Popen, PIPE)\n",
    "\n",
    "def status_job(slurm_jobid):\n",
    "                  \n",
    "    # build squeue command\n",
    "    squeue_args = ' -l -u ' + os.getenv('USER') + ' -j ' + slurm_jobid\n",
    "    squeue_cmd = ['squeue'] + squeue_args.split()\n",
    "    print(\"squeue_cmd = \", squeue_cmd)\n",
    "\n",
    "    # show status\n",
    "    squeue_out = ''\n",
    "    process = Popen(squeue_cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if stderr:\n",
    "        print(stdout.decode(\"utf-8\"))\n",
    "        print(stderr.decode(\"utf-8\"))\n",
    "        #raise IpyExit\n",
    "    return stdout.decode(\"utf-8\")\n",
    "\n",
    "def get_slurm_jobid(sbatchout_file):\n",
    "\n",
    "    # get slurm job id from file\n",
    "    if os.path.exists(sbatchout_file):\n",
    "        with open(sbatchout_file) as ifile:\n",
    "            for line in ifile:\n",
    "                if 'jobid:' in line:\n",
    "                    slurm_jobid = line.split()[-1]\n",
    "                    print(\"slurm_jobid = \", slurm_jobid)\n",
    "                    return slurm_jobid\n",
    "    else:\n",
    "        print(\"ERROR: not found \" + sbatchout_file)\n",
    "\n",
    "# get job id\n",
    "sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "\n",
    "# call 'squeue'\n",
    "if slurm_jobid_ia:            \n",
    "    squeue_out_ia = status_job(slurm_jobid_ia)\n",
    "    print(squeue_out_ia)\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check output directory (sample_ia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get job id\n",
    "sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "\n",
    "if not slurm_chain:\n",
    "\n",
    "    # SCRATCH\n",
    "    scratch_dir = os.getenv(\"SCRATCH_\" + cmpprj_name)\n",
    "    if slurm_jobid_ia and scratch_dir:\n",
    "        job_scratchdir_ia = os.path.join(scratch_dir, \"run_\" + slurm_jobid_ia)\n",
    "        print(\"job_scratchdir_ia = \", job_scratchdir_ia)\n",
    "        if not os.path.exists(job_scratchdir_ia):\n",
    "            print(\"scratch directory missing - perhaps the job has not started yet\")\n",
    "        #%ls -la $job_scratchdir_ia\n",
    "\n",
    "    # data output\n",
    "    job_outdir_ia = os.path.join(source_data_dir, \"ia_effect_samples\")\n",
    "    print(\"job_outdir_ia = \", job_outdir_ia)\n",
    "    if not os.path.exists(job_outdir_ia):\n",
    "        print(\"output directory mission - perhaps the job has not started yet\")\n",
    "        raise IpyExit\n",
    "    #%ls -la $job_outdir_ia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "## Simulation 2: Sample Posterior (4x)\n",
    "`sample_posterior.py` reads  \n",
    "- ./data/counties/counties.pkl\n",
    "- ./data/ia_effect_samples/covid19_{}.pkl\n",
    "\n",
    "and outputs:\n",
    "- ../data/mcmc_samples_backup/\n",
    "\n",
    "sample_posterior.py is called 4x by SLURM for add combinations defined in src/config.py:\n",
    "- gridjob_sample_posterior.slurm \n",
    "  - `#SBATCH --array=1-4:8`\n",
    "- gridjob_sample_posterior.slurm.sh\n",
    "  - `THEANO_FLAGS=\"base_compiledir=${TASK_DIR}/,floatX=float32,device=cpu,openmp=True,mode=FAST_RUN,warn_float64=warn\" python3 sample_posterior.py > ${TASK_DIR}/log.txt`\n",
    "- sample_posterior.py\n",
    "  - ```i = int(os.environ[\"SGE_TASK_ID\"])-1\n",
    "model_complexity, disease = combinations[i]\n",
    "filename_params = \"../data/mcmc_samples_backup/parameters_{}_{}_{}\".format(disease, use_interactions, use_report_delay)\n",
    "filename_pred = \"../data/mcmc_samples_backup/predictions_{}_{}_{}.pkl\".format(disease, use_interactions, use_report_delay)\n",
    "filename_model = \"../data/mcmc_samples_backup/model_{}_{}_{}.pkl\".format(disease, use_interactions, use_report_delay)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# check for SLURM job file\n",
    "slurm_jobfile_post = os.path.join(source_dir, 'src', \"gridjob_sample_posterior.slurm\")\n",
    "if not os.path.exists(slurm_jobfile_post):\n",
    "    print(\"ERROR: original SLURM job file does not exist\")\n",
    "    print(\"       please check for \", slurm_jobfile_post)\n",
    "    raise IpyExit\n",
    "else:\n",
    "    print(\"slurm_jobfile_post = \", slurm_jobfile_post)\n",
    "\n",
    "slurm_shfile_post = os.path.join(source_dir, 'src', \"gridjob_sample_posterior.slurm.sh\")\n",
    "if not os.path.exists(slurm_shfile_post):\n",
    "    print(\"ERROR: original SLURM sh file does not exist\")\n",
    "    print(\"       please check for \", slurm_shfile_post)\n",
    "    raise IpyExit\n",
    "print(\"slurm_shfile_ia = \", slurm_shfile_post)\n",
    "    \n",
    "# check is shell-script has executable bit\n",
    "if not os.access(slurm_shfile_post, os.X_OK):\n",
    "    with open(slurm_shfile_post, \"r\") as fd:\n",
    "        os.fchmod(fd.fileno(), 0o755)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    # check required input\n",
    "    file_counties = os.path.join(source_data_dir, 'counties', 'counties.pkl')\n",
    "    if not os.path.isfile(file_counties):\n",
    "        print(\"ERROR: file data/counties.pkl is missing\")\n",
    "        raise IpyExit\n",
    "    else:\n",
    "        print(\"file_counties = \", file_counties)\n",
    "\n",
    "    if not slurm_chain:\n",
    "        # check output of sample_ia (only if we slurm dependencies)\n",
    "        dir_iaeffect = os.path.join(source_data_dir, 'ia_effect_samples')\n",
    "        for i in range(100):\n",
    "            file_iaeffect = os.path.join(dir_iaeffect, \"covid19_{}.pkl\".format(i))\n",
    "            if not os.path.isfile(file_iaeffect):\n",
    "                print(\"ERROR: file \" + file_iaeffect + \"  is missing\")\n",
    "                raise IpyExit\n",
    "        print(\"file_iaeffect = \" + dir_iaeffect + \"/covid19_{}.pkl\")\n",
    "    \n",
    "    # check output directory\n",
    "    dir_mcmcsamples = os.path.join(source_data_dir, 'mcmc_samples_backup')\n",
    "    if not os.path.exists(dir_mcmcsamples):\n",
    "        os.mkdir(dir_mcmcsamples)\n",
    "    if not os.path.isdir(dir_mcmcsamples):\n",
    "        print(\"ERROR: \" + dir_mcmcsamples + \" not a directory\")\n",
    "        raise IpyExit\n",
    "    if os.listdir(dir_mcmcsamples):\n",
    "        print(\"ERROR: directory \" + dir_mcmcsamples + \" not empty\")\n",
    "        raise IpyExit\n",
    "    print(\"dir_mcmcsamples = \", dir_mcmcsamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare SLURM job file (sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "\n",
    "def prepare_jobfile_post(slurm_jobfile_post):\n",
    "    \n",
    "    # replace lines with user-info\n",
    "    finput = fileinput.input(slurm_jobfile_post, inplace=1)\n",
    "    try:\n",
    "        for line in finput:\n",
    "            line = \"#SBATCH --array=1-{}:{}\\n\".format(job_post_nodes * job_post_taskspernode, job_post_taskspernode) if \"#SBATCH --array=\" in line else line\n",
    "            line = \"#SBATCH --ntasks-per-node={}\\n\".format(job_post_taskspernode) if \"#SBATCH --ntasks-per-node=\" in line else line\n",
    "            line = \"#SBATCH --nodes=1\\n\"                          if \"#SBATCH --nodes=\"       in line else line\n",
    "            line = \"#SBATCH --time={}\\n\".format(job_post_runtime) if \"#SBATCH --time=\"        in line else line\n",
    "            line = \"#SBATCH --mail-type=ALL\\n\"                    if \"# #SBATCH --mail-type=\" in line else line\n",
    "            line = \"#SBATCH --mail-user=\" + user_email + '\\n'     if \"# #SBATCH --mail-user=\" in line else line\n",
    "            line = \"# mkdir -p ${PROJECT}/${USER}/runs/\\n\" if \"mkdir -p ${PROJECT}/${USER}/runs/\" in line else line\n",
    "            line = \"srun -n ${SLURM_NTASKS} gridjob_sample_posterior.slurm.sh\" if \"srun --exclusive -n ${SLURM_NTASKS} gridjob_sample_posterior.slurm.sh\\n\" in line else line\n",
    "            print(line, end='')\n",
    "    except:\n",
    "        print(\"ERROR: could not prepare slurm job file\")\n",
    "        raise IpyExit\n",
    "    finput.close()\n",
    "\n",
    "if submit_job_post:\n",
    "    prepare_jobfile_post(slurm_jobfile_post)\n",
    "    with open(slurm_jobfile_post, 'r') as sfile:\n",
    "        print(sfile.read())\n",
    "else:\n",
    "    print(\"NO submit of slurm ia job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit SLURM job (sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_dir_post = os.path.join(source_dir, 'src')\n",
    "print(\"submit_dir_post = \", submit_dir_post)\n",
    "\n",
    "if submit_job_post:\n",
    "    \n",
    "    sbatch_addargs = '-vv'\n",
    "\n",
    "    if slurm_chain:\n",
    "        sbatchout_file_ia = os.path.join(submit_dir_ia, slurm_jobfile_ia + \".sbatchout\")\n",
    "        slurm_jobid_ia = get_slurm_jobid(sbatchout_file_ia)\n",
    "        if slurm_jobid_ia:\n",
    "            sbatch_addargs += \" --dependency=aftercorr:{}\".format(slurm_jobid_ia)\n",
    "    \n",
    "    submit_job(slurm_jobfile_post, submit_dir_post, sbatch_addargs)\n",
    "    \n",
    "    # better wait for a few seconds to ensure slurm has processed the new job internally\n",
    "    # this ensures, that squeue will show at least some information\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    print(\"NO submit of slurm job\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show status of submitted job (sample_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get job id\n",
    "sbatchout_file_post = os.path.join(submit_dir_post, slurm_jobfile_post + \".sbatchout\")\n",
    "slurm_jobid_post = get_slurm_jobid(sbatchout_file_post)\n",
    "\n",
    "# call 'squeue'\n",
    "if slurm_jobid_post:\n",
    "    squeue_out_post = status_job(slurm_jobid_post)\n",
    "    print(squeue_out_post)\n",
    "else:\n",
    "    print(\"ERROR: no slurm job id found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid19dynstat_v01",
   "language": "python",
   "name": "covid19dynstat_v01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
