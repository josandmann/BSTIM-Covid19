{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Strategie - STEP 5\n",
    "\n",
    "- threading of for-j-county-loop (done)\n",
    "- theano optimizations (missing)\n",
    "- NO reallocate memory for x_data_all all the time (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A - Read/Create Input Data\n",
    "* output:\n",
    "  - kw_data\n",
    "  - day_data\n",
    "  - time_by_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('../data/counties/counties.pkl', \"rb\") as f:\n",
    "    counties = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = \"covid19\"\n",
    "prediction_region = \"germany\"\n",
    "def load_daily_data(disease, prediction_region, counties, seperator=\",\"):\n",
    "    data = pd.read_csv(\"../data/diseases/{}.csv\".format(disease),\n",
    "                       sep=seperator, encoding='iso-8859-1', index_col=0)\n",
    "\n",
    "    if \"99999\" in data.columns:\n",
    "        data.drop(\"99999\", inplace=True, axis=1)\n",
    "\n",
    "    data = data.loc[:, list(\n",
    "        filter(lambda cid: prediction_region in counties[cid][\"region\"], data.columns))]\n",
    "    data.index = [pd.Timestamp(date) for date in data.index]\n",
    "\n",
    "    return data\n",
    "indata = load_daily_data(disease, prediction_region, counties)\n",
    "data = indata\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create times_by_day dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "rnd_tsel = np.random.Generator(np.random.PCG64(12345))\n",
    "\n",
    "def uniform_times_by_day(days, n=10):\n",
    "    \"\"\" Samples n random timepoints within a day, per day. converts pd.Timestamps to datetime obj.\"\"\"\n",
    "    res = OrderedDict()\n",
    "    for day in days:\n",
    "        time_min = datetime.datetime.combine(day, datetime.time.min)\n",
    "        time_max = datetime.datetime.combine(day, datetime.time.max)\n",
    "        res[day] = rnd_tsel.random(n) * (time_max - time_min) + time_min\n",
    "    return res\n",
    "\n",
    "times_by_day=uniform_times_by_day(data.index)\n",
    "#times_by_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create locations_by_county dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "rnd_csel = np.random.Generator(np.random.PCG64(12345))\n",
    "\n",
    "def uniform_locations_by_county(counties, n=5):\n",
    "    res = OrderedDict()\n",
    "    for (county_id, county) in counties.items():\n",
    "        tp = county[\"testpoints\"]\n",
    "        if n == len(tp):\n",
    "            res[county_id] = tp\n",
    "        else:\n",
    "            idx = rnd_csel.choice(tp.shape[0], n, replace=n > len(tp))\n",
    "            res[county_id] = tp[idx]\n",
    "    return res\n",
    "\n",
    "locations_by_county=uniform_locations_by_county(counties)\n",
    "#locations_by_county"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define temporal_bfs and spatial_bfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_bf(dx, σ):\n",
    "    \"\"\" spatial basis function \"\"\"\n",
    "    σ = np.float32(σ)\n",
    "    res = tt.zeros_like(dx)\n",
    "    idx = (abs(dx) < np.float32(5) * σ)  # .nonzero()\n",
    "    return tt.set_subtensor(res[idx], tt.exp(\n",
    "        np.float32(-0.5 / (σ**2)) * (dx[idx])**2) / np.float32(np.sqrt(2 * np.pi * σ**2)))\n",
    "\n",
    "\n",
    "def bspline_bfs(x, knots, P):\n",
    "    \"\"\" temporal basis function\n",
    "            x: t-delta distance to last knot (horizon 5)\n",
    "    \"\"\"\n",
    "    knots = knots.astype(np.float32)\n",
    "    idx = ((x >= knots[0]) & (x < knots[-1]))  # .nonzero()\n",
    "    xx = x[idx]\n",
    "\n",
    "    N = {}\n",
    "    for p in range(P + 1):\n",
    "        for i in range(len(knots) - 1 - p):\n",
    "            if p == 0:\n",
    "                N[(i, p)] = tt.where((knots[i] <= xx)\n",
    "                                     * (xx < knots[i + 1]), 1.0, 0.0)\n",
    "            else:\n",
    "                N[(i, p)] = (xx - knots[i]) / (knots[i + p] - knots[i]) * N[(i, p - 1)] + \\\n",
    "                    (knots[i + p + 1] - xx) / (knots[i + p + 1] - knots[i + 1]) * N[(i + 1, p - 1)]\n",
    "\n",
    "    highest_level = []\n",
    "    for i in range(len(knots) - 1 - P):\n",
    "        res = tt.zeros_like(x)\n",
    "        highest_level.append(tt.set_subtensor(res[idx], N[(i, P)]))\n",
    "    return highest_level\n",
    "\n",
    "\n",
    "#NOTE: Do we want basis functions with a longer temporal horizon? // we may want to weight them around fixed days?!\n",
    "#NOTE: Split this up, so we can get multiple basis functions!\n",
    "def temporal_bfs(x):\n",
    "    return bspline_bfs(x, np.array([0, 0, 1, 2, 3, 4, 5]) * 24 * 3600.0, 2) \n",
    "\n",
    "\n",
    "def spatial_bfs(x):\n",
    "    return [gaussian_bf(x, σ) for σ in [6.25, 12.5, 25.0, 50.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Theano function ia_bfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_sq(latitude, R=6365.902):\n",
    "    \"\"\"\n",
    "        jacobian_sq(latitude)\n",
    "\n",
    "    Computes the \"square root\" (Cholesky factor) of the Jacobian of the cartesian projection from polar coordinates (in degrees longitude, latitude) onto cartesian coordinates (in km east/west, north/south) at a given latitude (the projection's Jacobian is invariante wrt. longitude).\n",
    "    TODO: don't import jacobian_sq from geo_utils to remove potential conflicts\n",
    "    \"\"\"\n",
    "    return R * (np.pi / 180.0) * (abs(tt.cos(tt.deg2rad(latitude))) *\n",
    "                                  np.array([[1.0, 0.0], [0.0, 0.0]]) + np.array([[0.0, 0.0], [0.0, 1.0]]))\n",
    "\n",
    "\n",
    "def build_ia_bfs(temporal_bfs, spatial_bfs, profile):\n",
    "    x1 = tt.fmatrix(\"x1\")\n",
    "    t1 = tt.fvector(\"t1\")\n",
    "    # M = tt.fmatrix(\"M\")\n",
    "    x2 = tt.fmatrix(\"x2\")\n",
    "    t2 = tt.fvector(\"t2\")\n",
    "\n",
    "    lat = x1[:, 1].mean()\n",
    "    M = jacobian_sq(lat)**2\n",
    "\n",
    "    # (x1,t1) are the to-be-predicted points, (x2,t2) the historic cases\n",
    "\n",
    "    # spatial distance btw. each points (defined with latitude,longitude) in x1 and x2 with gramian M\n",
    "    # (a-b)^2 = a^2 + b^2 -2ab; with a,b=vectors\n",
    "    dx = tt.sqrt(  (x1.dot(M) * x1).sum(axis=1).reshape((-1,  1)) # a^2\n",
    "                 + (x2.dot(M) * x2).sum(axis=1).reshape(( 1, -1)) # b^2\n",
    "                 - 2 * x1.dot(M).dot(x2.T) )                      # -2ab\n",
    "\n",
    "    # temporal distance btw. each times in t1 and t2\n",
    "    dt = t1.reshape((-1, 1)) - t2.reshape((1, -1))\n",
    "\n",
    "    ft = tt.stack(temporal_bfs(dt.reshape((-1,))), axis=0) # cast to floats?\n",
    "    fx = tt.stack(spatial_bfs(dx.reshape((-1,))), axis=0)\n",
    "\n",
    "    # aggregate contributions of all cases\n",
    "    contrib = ft.dot(fx.T).reshape((-1,)) / tt.cast(x1.shape[0], \"float32\")\n",
    "\n",
    "    return theano.function([t1, x1, t2, x2], contrib, allow_input_downcast=True, profile=profile)\n",
    "\n",
    "ia_bfs = build_ia_bfs(temporal_bfs, spatial_bfs, profile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/software/jureca/Stages/Devel-2019a/software/Python/3.6.8-GCCcore-8.3.0/lib/python3.6/site-packages/theano/tensor/subtensor.py:2197: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n",
      "/usr/local/software/jureca/Stages/Devel-2019a/software/Python/3.6.8-GCCcore-8.3.0/lib/python3.6/site-packages/theano/tensor/subtensor.py:2339: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.59058740e-07,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.42673556e-08,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_ia_bfs = build_ia_bfs(temporal_bfs, spatial_bfs, profile=True)\n",
    "#theano.printing.debugprint(profile_ia_bfs)\n",
    "\n",
    "# test ia_bfs()\n",
    "t1=[1580234892.375513, 1580224126.122202, 1580193367.920551, 1580193367.920551, 1580185641.832341, 1580194755.123367]\n",
    "x1 = [ [10.435944369180099, 51.69958916804793],\n",
    "       [10.435944369180099, 51.69958916804793],\n",
    "       [10.134378974970323, 51.51153765399198],\n",
    "       [10.134378974970323, 51.51153765399198],\n",
    "       [10.435944369180099, 51.69958916804793],\n",
    "       [10.97023632180951,  49.35209111265112],]\n",
    "t2=[1580234892.375513, 1580224428.403552, 1580182133.833636, 1580217693.876309, 1580224428.403552, 1580224428.403552,]\n",
    "x2 = [ [11.38965623, 48.0657035 ],\n",
    "       [11.0615104 , 48.11177134],\n",
    "       [ 7.12902758, 51.57865701],\n",
    "       [ 7.12902758, 51.57865701],\n",
    "       [11.38965623, 48.0657035 ],\n",
    "       [11.0615104 , 48.11177134],]\n",
    "profile_ia_bfs(t1,x1,t2,x2)\n",
    "#profile_ia_bfs.profile.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Do the Sampling (the old way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed to check results\n",
    "rnd_time = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc  = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_time_pred = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc_pred  = np.random.Generator(np.random.PCG64(12345))\n",
    "\n",
    "# random generators:\n",
    "# MT19937, PCG64, Philox, SFC64 - https://numpy.org/devdocs/reference/random/bit_generators/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# loop over all days of all counties\n",
    "# and draw per day n-times a random time from times_by_day[day]\n",
    "\n",
    "def sample_time_and_space(data, times_by_day, locations_by_county, rnd_t, rnd_l):\n",
    "    n_total = data.sum().sum()\n",
    "    t_all = np.empty((n_total,), dtype=object)\n",
    "    x_all = np.empty((n_total, 2))\n",
    "    \n",
    "    i=0\n",
    "    for (county_id, series) in data.iteritems():\n",
    "        for (day, n) in series.iteritems():\n",
    "            #if n==0: continue\n",
    "            #print(i,\"\\n   day =\",day,\"\\n   no. samples to draw = \",n)\n",
    "        \n",
    "            # draw n random times\n",
    "            times = times_by_day[day]\n",
    "            #idx = rnd_time.choice(len(times), n)\n",
    "            idx = np.floor( (n*[len(times)]) * rnd_t.random((n,)) ).astype(\"int32\") # replace 'rnd_time.choice' to enable compare with new optimized solution\n",
    "            #print(\"   random sample ids   = \",idx)\n",
    "            t_all[i:i + n] = times[idx]\n",
    "\n",
    "            # draw n random locations\n",
    "            locs = locations_by_county[county_id]\n",
    "            #idx = rnd_loc.choice(locs.shape[0], n)\n",
    "            idx = np.floor( (n*[locs.shape[0]]) * rnd_l.random((n,)) ).astype(\"int32\") # replace 'rnd_time.choice' to enable compare with new optimized solution\n",
    "            x_all[i:i + n, :] = locs[idx, :]\n",
    "        \n",
    "            i += n          \n",
    "\n",
    "    return t_all, x_all\n",
    "\n",
    "t_data_0 = []\n",
    "x_data_0 = []\n",
    "t_pred_0 = []\n",
    "x_pred_0 = []\n",
    "\n",
    "num_tps=5\n",
    "d_offs=0 # just to limit the time of test\n",
    "c_offs=0 # just to limit the time of test\n",
    "days = data.index[d_offs:d_offs+50]\n",
    "counties = data.columns[c_offs:c_offs+50]\n",
    "\n",
    "_to_timestamp = np.frompyfunc(datetime.datetime.timestamp, 1, 1)\n",
    "num_features = len(temporal_bfs(tt.fmatrix(\"tmp\"))) * len(spatial_bfs(tt.fmatrix(\"tmp\")))\n",
    "res_0 = np.zeros((len(days), len(counties), num_features), dtype=np.float32)\n",
    "\n",
    "for i, day in enumerate(days):\n",
    "    for j, county in enumerate(counties):\n",
    "        idx = ((day - pd.Timedelta(days=5)) <= data.index) * (data.index < day)\n",
    "\n",
    "        t_data, x_data = sample_time_and_space(data.iloc[idx], times_by_day, locations_by_county, rnd_time, rnd_loc)\n",
    "        t_pred, x_pred = sample_time_and_space(pd.DataFrame(num_tps, index=[day], columns=[county]), times_by_day, locations_by_county, rnd_time_pred, rnd_loc_pred)\n",
    "        \n",
    "        #print(\"_to_timestamp(t_pred) (types, type1, size, value): \", type(_to_timestamp(t_pred)), type(_to_timestamp(t_pred)[0]), np.shape(_to_timestamp(t_pred)), _to_timestamp(t_pred)[0])\n",
    "        # => _to_timestamp(t_pred) (types, type1, size, value):  <class 'numpy.ndarray'> <class 'float'> (5,) 1580217693.876309\n",
    "        #print(\"x_pred (types, size, value)       : \", type(x_pred), type(x_pred[0]), type(x_pred[0][0]), np.shape(x_pred), x_pred[0][0])        \n",
    "        # => x_pred (types, size, value)       :  <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.float64'> (5, 2) 10.134378974970323\n",
    "        \n",
    "        res_0[i, j, :] = ia_bfs(_to_timestamp(t_pred), x_pred, _to_timestamp(t_data), x_data)        \n",
    "        \n",
    "        # store all to compare with old algo\n",
    "        t_data_0 = t_data_0 + t_data.tolist()\n",
    "        x_data_0 = x_data_0 + x_data.tolist()\n",
    "        t_pred_0 = t_pred_0 + t_pred.tolist()\n",
    "        x_pred_0 = x_pred_0 + x_pred.tolist()\n",
    "\n",
    "######## output ########\n",
    "#display(t_data_0[:2])\n",
    "#display(x_data_0[:2])\n",
    "#display(t_pred_0[:2])\n",
    "#display(x_pred_0[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_0[1:2][:][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C - Do the Sampling (the NEW way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## C3 - COMPACT result\n",
    "* requires (A) to be finished -> data, times_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_time_and_space__once(times_by_day, locations_by_county):\n",
    "    \"\"\" \n",
    "    Convert dictonarys to arrays for faster access in sample_time_and_space().\n",
    "  \n",
    "    Random access in times_by_day and locations_by_county are very costy.\n",
    "    Hence they need to be converted to arrays and access must be done through indexes.\n",
    "    \"\"\"\n",
    "    # times_by_day_np[day-id] => times[n_times]\n",
    "    times_by_day_np = pd.DataFrame.from_dict(times_by_day,orient='index').to_numpy(dtype='datetime64') # => type=='numpy.datetime64'\n",
    "    \n",
    "    t_convert_1 = np.frompyfunc(pd.Timestamp, 1, 1)\n",
    "    times_by_day_np = t_convert_1(times_by_day_np) # => type=='pandas._libs.tslibs.timestamps.Timestamp'\n",
    "    \n",
    "    t_convert_2 = np.frompyfunc(datetime.datetime.timestamp, 1, 1)    \n",
    "    times_by_day_np = t_convert_2(times_by_day_np) # => type=='float'\n",
    "    \n",
    "    # locations_by_county_np[county-id] => locs[m_locs[x,y]]\n",
    "    max_coords = 0\n",
    "    for item in locations_by_county.items():\n",
    "        max_coords = max( len(item[1]), max_coords)\n",
    "    locations_by_county_np = np.empty([len(locations_by_county.keys()), max_coords, 2], dtype='float64')\n",
    "    for i,item in enumerate(locations_by_county.items()): # counties are sorted because of OrderedDict\n",
    "        locations_by_county_np[i][:] = item[1][:]\n",
    "        \n",
    "    return(times_by_day_np, locations_by_county_np)\n",
    "\n",
    "#times_by_day_np, locations_by_county_np = sample_time_and_space__once(times_by_day, locations_by_county)\n",
    "#print(\"locations_by_county_np (types, size, value) : \",\n",
    "#      type(locations_by_county_np),\n",
    "#      type(locations_by_county_np[0]),\n",
    "#      type(locations_by_county_np[0][0]),\n",
    "#      np.shape(locations_by_county_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_time_and_space__prep(times_by_day_np, locations_by_county_np, data, idx):\n",
    "    \"\"\" \n",
    "    Recalculations for a fixed dataframe sample_time_and_space().\n",
    "  \n",
    "    Calculation of helper arrays are very costy.\n",
    "    If the dataframe does not change, precalculated values can be reused.\n",
    "    \"\"\"\n",
    "\n",
    "    # subdata 'data' of 'indata' is likely to skip a few first days(rows) in 'indata',\n",
    "    # but as times_by_day_np represents the whole 'indata', an offsets needs to be considered when accessing 'times_by_day_np'\n",
    "    dayoffset = np.where(idx==True)[0][0]   \n",
    "    n_total = data.sum().sum()\n",
    "\n",
    "    # get number of samples per county-day\n",
    "    smpls_per_cntyday = np.array(data.values).flatten('F')\n",
    "\n",
    "    ######## t_all ########\n",
    "\n",
    "    # get list of day-ids for all county-days\n",
    "    dayids = np.arange(len(data.index))\n",
    "    day_of_cntyday = np.tile(dayids, len(data.columns))\n",
    "\n",
    "    # get list of day-ids for all samples\n",
    "    day_of_smpl = [ day_of_cntyday[i] for (i,smpls) in enumerate(smpls_per_cntyday) for x in range(smpls) ]  \n",
    "\n",
    "    # get available times for each sample\n",
    "    time_of_days = data.index.tolist() # cannot be a np.array as it needs to stay a pandas.timeformat\n",
    "    av_times_per_day = [len(times_by_day[d]) for d in time_of_days]\n",
    "    av_times_per_smpl = [ av_times_per_day[day_of_cntyday[i]] for (i,smpls) in enumerate(smpls_per_cntyday) for x in range(smpls) ]\n",
    "    \n",
    "    ######## x_all ########\n",
    "\n",
    "    # get list of county-ids for all county-days\n",
    "    cntyids = np.arange(len(data.columns))\n",
    "    cnty_of_cntyday = np.repeat(cntyids, len(data.index))\n",
    "\n",
    "    # get list of county-ids for all samples\n",
    "    cnty_of_smpl = [ cnty_of_cntyday[i] for (i,smpl) in enumerate(smpls_per_cntyday) for x in range(smpl) ]\n",
    "\n",
    "    # get available locations for each sample\n",
    "    label_of_cntys = data.columns # list of countys labels\n",
    "    av_locs_per_cnty = [len(locations_by_county[c]) for c in label_of_cntys]\n",
    "    av_locs_per_smpl = [ av_locs_per_cnty[cnty_of_cntyday[i]] for (i,smpls) in enumerate(smpls_per_cntyday) for x in range(smpls) ]\n",
    "    \n",
    "    return (n_total, dayoffset,\n",
    "            day_of_smpl, av_times_per_smpl, \n",
    "            cnty_of_smpl, av_locs_per_smpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_time_and_space__pred(n_days, n_counties, d_offs, c_offs, num_tps, av_times_per_smpl, av_locs_per_smpl, rnd_time, rnd_loc):\n",
    "    \n",
    "    ######## t_all ########    \n",
    "    n_total = n_days * n_counties * num_tps\n",
    "    \n",
    "    rnd_timeid_per_smpl = np.floor( av_times_per_smpl * rnd_time.random( n_total ) ).astype(\"int32\")\n",
    "    \n",
    "    # collect times for each sample with its random time-id\n",
    "    t_all = [ times_by_day_np[d_offs+i][rnd_timeid_per_smpl[(i*n_counties+j)*num_tps+x]] for i in range(n_days) for j in range(n_counties) for x in range(num_tps) ] \n",
    "\n",
    "    ######## x_all ########\n",
    "\n",
    "    # calc random location-id for each sample\n",
    "    rnd_locid_per_smpl = np.floor( av_locs_per_smpl * rnd_loc.random((n_total,)) ).astype(\"int32\")\n",
    "\n",
    "    # collect locations for each sample with its random location-id\n",
    "    x_all = [ locations_by_county_np[c_offs+j][rnd_locid_per_smpl[(i*n_counties+j)*num_tps+x]] for i in range(n_days) for j in range(n_counties) for x in range(num_tps) ] \n",
    "    \n",
    "    return t_all, x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_time_and_space(n_counties, n_total, dayoffset, day_of_smpl, av_times_per_smpl, cnty_of_smpl, av_locs_per_smpl, rnd_time, rnd_loc):\n",
    "    \"\"\" \n",
    "    Calculations samples in time and space.\n",
    "  \n",
    "    Calculation a hughe random number array use precalulated results to pick samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    ######## t_all ########\n",
    "    \n",
    "    # calc random time-id for each sample\n",
    "    n_all = n_total * n_counties\n",
    "    \n",
    "    av_times_per_smpl_all = np.tile(av_times_per_smpl, n_counties)\n",
    "    rnd_timeid_per_smpl_all = np.floor( av_times_per_smpl_all * rnd_time.random( (n_all,) ) ).astype(\"int32\")\n",
    "\n",
    "    # collect times for each sample with its random time-id\n",
    "    #t_all = np.empty((n_total,), dtype=object) \n",
    "    t_all = [ times_by_day_np[day+dayoffset][rnd_timeid_per_smpl_all[j*n_total+i]] for j in range(n_counties) for (i,day) in enumerate(day_of_smpl) ] # [county][day][smpl]\n",
    "\n",
    "    ######## x_all ########\n",
    "\n",
    "    # calc random location-id for each sample\n",
    "    av_locs_per_smpl_all = np.tile(av_locs_per_smpl, n_counties)\n",
    "    rnd_locid_per_smpl_all = np.floor( av_locs_per_smpl_all * rnd_loc.random( (n_all,) ) ).astype(\"int32\")\n",
    "\n",
    "    # collect locations for each sample with its random location-id\n",
    "    #x_all = np.empty((n_total, 2))\n",
    "    #print(\"x_all (types, size, value)       : \", type(x_all), np.shape(x_all) )   \n",
    "    x_all = [ locations_by_county_np[cnty][rnd_locid_per_smpl_all[j*n_total+i]] for j in range(n_counties) for (i,cnty) in enumerate(cnty_of_smpl)] # [county][day][smpl]\n",
    "    if not x_all:\n",
    "        x_all = np.empty((0, 2)) # ensure array is always 2-dimensional, even then it is empty\n",
    "    \n",
    "    return t_all, x_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def theano_for_county(i, j, n_counties, num_tps, t_pred_all, x_pred_all, t_data_all, x_data_all, ia_bfs_thread, res):\n",
    "\n",
    "    # calcs only for the single DataFrame.cell[day][county]\n",
    "    offs = (i*n_counties+j)*num_tps\n",
    "    t_pred = t_pred_all[offs:offs+num_tps] \n",
    "    x_pred = x_pred_all[offs:offs+num_tps] \n",
    "    \n",
    "    # get subarray for county==j\n",
    "    t_data = t_data_all[j*n_total:(j+1)*n_total] # [county][smpl]\n",
    "    x_data = x_data_all[j*n_total:(j+1)*n_total] # [county][smpl]\n",
    "             \n",
    "    # use theano.function for day==i and county==j\n",
    "    t = int(threading.current_thread().name.split(\"_\")[1]) # get worker id from worker name\n",
    "    res[i, j, :] = ia_bfs_thread[t](t_pred, x_pred, t_data, x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "# set seed to check results\n",
    "# Parallel Random Number Generation - https://docs.scipy.org/doc/numpy/reference/random/parallel.html\n",
    "# Multithreaded Generation - https://docs.scipy.org/doc/numpy/reference/random/multithreading.html\n",
    "rnd_time = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc  = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_time_pred = np.random.Generator(np.random.PCG64(12345))\n",
    "rnd_loc_pred  = np.random.Generator(np.random.PCG64(12345))\n",
    "\n",
    "# create a copy of the theano function for each worker thread\n",
    "workers = 12\n",
    "ia_bfs_thread = []\n",
    "for w in range(workers):\n",
    "    #ia_bfs_tmp = ia_bfs.copy(share_memory=False, swap=None, delete_updates=False, name=None, profile=None) # fails when used <======= MUCH BETTER, BUT RETURNS ONLY ZEROS\n",
    "    ia_bfs_tmp = build_ia_bfs(temporal_bfs, spatial_bfs, profile=False)\n",
    "    ia_bfs_thread.append(ia_bfs_tmp)\n",
    "\n",
    "# Convert dictonarys to arrays for faster access in sample_time_and_space().\n",
    "(times_by_day_np, locations_by_county_np,) = sample_time_and_space__once(times_by_day, locations_by_county)\n",
    "\n",
    "t_data_1 = []\n",
    "x_data_1 = []\n",
    "t_pred_1 = []\n",
    "x_pred_1 = []\n",
    "\n",
    "d_offs=0 # just to limit the time of test\n",
    "c_offs=0 # just to limit the time of test\n",
    "days = data.index[d_offs:d_offs+50]\n",
    "counties = data.columns[c_offs:c_offs+50]\n",
    "\n",
    "num_features = len(temporal_bfs(tt.fmatrix(\"tmp\"))) * len(spatial_bfs(tt.fmatrix(\"tmp\")))\n",
    "res_1 = np.zeros((len(days), len(counties), num_features), dtype=np.float32)\n",
    "\n",
    "num_tps=5\n",
    "n_days = len(days)\n",
    "n_counties = len(counties)\n",
    "\n",
    "# create dataframe with 'num_tps' in each cell\n",
    "pred_data = pd.DataFrame(num_tps, index=days, columns=counties)\n",
    "idx = np.empty([len(data.index)], dtype='bool')\n",
    "idx.fill(True)\n",
    "\n",
    "# precalculate pediction values\n",
    "(n_total, dayoffset, day_of_smpl, av_times_per_smpl, cnty_of_smpl, av_locs_per_smpl,) = sample_time_and_space__prep(times_by_day_np, locations_by_county_np, pred_data, idx)\n",
    "(t_pred_all, x_pred_all,) = sample_time_and_space__pred(n_days, n_counties, d_offs, c_offs, num_tps, av_times_per_smpl, av_locs_per_smpl, rnd_time_pred, rnd_loc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the futures within this thread pool\n",
    "from concurrent.futures import ThreadPoolExecutor, wait\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=workers, thread_name_prefix='worker') as executor:\n",
    "    \n",
    "    for i, day in enumerate(days):\n",
    "    \n",
    "        # calc which sub-table will be selected\n",
    "        idx = ((day - pd.Timedelta(days=5)) <= data.index) * (data.index < day)\n",
    "        subdata = data.iloc[idx]\n",
    "    \n",
    "        if subdata.size != 0:\n",
    "            # Recalculations for a fixed dataframe sample_time_and_space().\n",
    "            (n_total, dayoffset, day_of_smpl, av_times_per_smpl, cnty_of_smpl, av_locs_per_smpl,) = sample_time_and_space__prep(times_by_day_np, locations_by_county_np, subdata, idx)    \n",
    "\n",
    "            # Calculate time and space samples for all counties at once\n",
    "            (t_data_all, x_data_all,) = sample_time_and_space(len(counties), n_total, dayoffset, day_of_smpl, av_times_per_smpl, cnty_of_smpl, av_locs_per_smpl, rnd_time, rnd_loc)\n",
    "\n",
    "            futures = [executor.submit(theano_for_county, i, j, n_counties, num_tps, t_pred_all, x_pred_all, t_data_all, x_data_all, ia_bfs_thread, res_1) for j, county in enumerate(counties)]\n",
    "            wait(futures, timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_1[1:2][:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(res_0, res_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
